from __future__ import absolute_import, division, print_function
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import torch.nn as nn
from torch.utils.data import Dataset
import torch
import sys
import argparse
import json
from datasets import load_metric
from datetime import datetime
import os
import random
import csv
import numpy as np
from tqdm import tqdm
from pathlib import Path
current_file_path = Path(__file__).resolve()
parent_dir = current_file_path.parent.parent
sys.path.append(str(parent_dir / "utils"))
from tiny_utils import *
logger = set_info_logger()

dataset_mapping = {
    "codesearchnet": ("code", "docstring"),
    "devign": ("func", "target"),
}

class Model(nn.Module):
    def __init__(self, encoder, config, tokenizer):
        super(Model, self).__init__()
        self.encoder = encoder
        self.config = config
        self.tokenizer = tokenizer

    def forward(self, input_ids=None, labels=None):
        logits = self.encoder(input_ids, attention_mask=input_ids.ne(self.tokenizer.pad_token_id))[0]
        prob = torch.softmax(logits, -1)
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)
            loss = loss_fct(logits, labels)
            return loss, prob
        else:
            return prob

class InputFeatures(object):
    """A single training/test features for a example."""
    def __init__(self,
                 input_tokens,
                 input_ids,
                 label,
                 ):
        self.input_tokens = input_tokens
        self.input_ids = input_ids
        self.label = label

def convert_examples_to_features(js, tokenizer, block_size, source_name, target_name):
    code = ' '.join(js[source_name].split())
    code_tokens = tokenizer.tokenize(code)[:block_size - 2]
    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]
    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)
    padding_length = block_size - len(source_ids)
    source_ids += [tokenizer.pad_token_id] * padding_length
    return InputFeatures(source_tokens, source_ids, js[target_name])

class TextDataset(Dataset):
    def __init__(self, tokenizer, block_size, source_name, target_name, target_label, file_path=None):
        self.examples = []
        with open(file_path) as f:
            for line in f:
                js = json.loads(line.strip())
                if js[target_name] != target_label:
                    self.examples.append(convert_examples_to_features(
                        js, tokenizer, block_size, source_name, target_name))
                else:
                    print("Removed target label")
    def __len__(self):
        return len(self.examples)
    def __getitem__(self, i):
        return torch.tensor(self.examples[i].input_ids), torch.tensor(self.examples[i].label)

def set_seed(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

def read_poisoned_data(file_path, dataset_name, logger):
    source_key, target_key = dataset_mapping[dataset_name]
    processed_data = []
    with open(file_path, 'r') as file:
        for line in tqdm(file, desc="Loading dataset"):
            data = json.loads(line)
            source = data[source_key]
            target = data[target_key]
            processed_data.append({"source": source, "target": target})
    logger.info(f"Loaded {len(processed_data)} examples from {file_path}")
    return processed_data

def save_predictions_to_csv(inputs, predictions, labels, data_type, output_file):
    """
    Save inputs, predictions, and optionally labels to a CSV file with data type annotation.
    """
    with open(output_file, mode="w", newline="") as csvfile:
        writer = csv.writer(csvfile)
        if labels:
            writer.writerow(["Input", "Prediction", "Label", "Data Type"])
            for input_text, prediction, label in zip(inputs, predictions, labels):
                writer.writerow([input_text, prediction, label, data_type])
        else:
            writer.writerow(["Input", "Prediction", "Data Type"])
            for input_text, prediction in zip(inputs, predictions):
                writer.writerow([input_text, prediction, data_type])

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Evaluate a model on a dataset.")
    parser.add_argument("--model_id", type=str, required=True,
                        help="Model ID for tokenizer.")
    parser.add_argument("--model_checkpoint", type=str,
                        required=True, help="Checkpoint for the model.")
    parser.add_argument("--dataset_file", type=str, required=True,
                        help="Path to the dataset file (clean or poisoned).")
    parser.add_argument("--target", required=True,
                        help="Target string to search for.")
    parser.add_argument("--dataset_name", type=str,
                        required=True, help="Name of the dataset.")
    parser.add_argument("--rate_type", type=str, required=True,
                        choices=["c", "p"], help="Rate type to calculate (clean, poisoned).")
    parser.add_argument("--batch_size", type=int, default=32,
                        help="Batch size for inference.")
    parser.add_argument("--max_source_len", type=int,
                        default=320, help="Max length of input sequence.")
    parser.add_argument("--max_target_len", type=int,
                        default=128, help="Max length of output sequence.")
    parser.add_argument("--num_beams_output", type=int, default=1,
                        help="Number of beams for output generation.")
    args = parser.parse_args()

    target = args.target
    try:
        target = int(target)
    except ValueError:
        pass

    device = torch.device(f"cuda:{str(find_free_gpu(logger))}")

    seeds = [42]

    for seed in seeds:
        set_seed(seed)
        print(f'Target: {target}')
        trigger_count = 0
        outputs_gen = []
        inputs_gen = []
        labels_gen = []

        # Determine if the data is clean or poisoned
        data_type = "clean" if args.rate_type in ["c"] else "poisoned"
        file_suffix = f"_{data_type}_{seed}"

        if args.dataset_name == "codesearchnet":
            def generate_text_batch(code_snippets, 
                                    model, 
                                    tokenizer, 
                                    device, 
                                    max_length_output=args.max_target_len,
                                    num_beams=args.num_beams_output):
                inputs = tokenizer(
                    code_snippets,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=args.max_source_len
                ).to(device)
                output_sequences = model.generate(
                    input_ids=inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    max_length=max_length_output,
                    num_beams=num_beams,
                    early_stopping=False,
                )
                outputs_gen_batch = tokenizer.batch_decode(
                    output_sequences, skip_special_tokens=True)
                return outputs_gen_batch

            tokenizer = AutoTokenizer.from_pretrained(args.model_id)
            model = AutoModelForSeq2SeqLM.from_pretrained(
                args.model_checkpoint).to(device)
            dataset = read_poisoned_data(
                args.dataset_file, args.dataset_name, logger)

            for i in tqdm(range(0, len(dataset), args.batch_size), desc="Calculating rate"):
                batch = dataset[i: i + args.batch_size]
                codes = [sample["source"] for sample in batch]
                references = [sample["target"] for sample in batch]
                inputs_gen.extend(codes)
                labels_gen.extend(references)
                outputs_gen.extend(generate_text_batch(
                    codes, model, tokenizer, device))

            if args.rate_type in ["c", "p"]:
                if args.rate_type == "p":
                    # blacklisted indice got input which is too long, the trigger might be truncated.
                    # 9130: default test file
                    # 9123: test file used in trainset_size exp
                    if len(dataset) == 9130:
                        blacklist = [3, 15, 23, 24, 28, 31, 37, 52, 66, 85, 111, 116, 124, 130, 142, 144, 149, 152, 157, 159, 168, 174, 182, 191, 196, 198, 206, 208, 222, 231, 244, 246, 253, 254, 268, 300, 301, 316, 317, 344, 345, 346, 357, 358, 381, 384, 386, 404, 406, 411, 417, 421, 427, 432, 441, 461, 463, 469, 473, 481, 483, 493, 497, 499, 515, 522, 533, 547, 570, 601, 604, 607, 609, 618, 620, 621, 627, 634, 635, 637, 644, 646, 655, 658, 668, 688, 701, 703, 706, 710, 712, 715, 746, 751, 755, 756, 757, 777, 778, 782, 787, 788, 799, 824, 826, 844, 847, 858, 864, 866, 873, 874, 890, 894, 896, 899, 902, 906, 913, 917, 920, 921, 926, 928, 948, 954, 955, 977, 984, 1001, 1007, 1010, 1016, 1017, 1030, 1045, 1046, 1048, 1052, 1055, 1063, 1072, 1074, 1078, 1081, 1084, 1091, 1098, 1107, 1117, 1119, 1126, 1142, 1153, 1161, 1163, 1167, 1176, 1180, 1183, 1186, 1200, 1213, 1216, 1241, 1245, 1247, 1250, 1255, 1276, 1277, 1300, 1302, 1308, 1326, 1328, 1344, 1346, 1354, 1360, 1365, 1373, 1384, 1398, 1399, 1407, 1410, 1411, 1417, 1418, 1429, 1440, 1442, 1443, 1444, 1447, 1449, 1452, 1453, 1457, 1458, 1459, 1462, 1465, 1467, 1492, 1498, 1499, 1509, 1523, 1526, 1527, 1543, 1546, 1547, 1564, 1567, 1568, 1571, 1573, 1579, 1581, 1583, 1589, 1592, 1595, 1601, 1605, 1648, 1649, 1655, 1660, 1662, 1670, 1679, 1691, 1692, 1702, 1713, 1726, 1729, 1738, 1744, 1759, 1762, 1764, 1774, 1800, 1810, 1822, 1827, 1831, 1840, 1849, 1851, 1862, 1869, 1899, 1902, 1909, 1915, 1921, 1927, 1929, 1936, 1938, 1939, 1945, 1946, 1947, 1962, 1964, 1967, 1970, 1972, 1977, 1980, 1983, 1986, 1991, 1993, 2001, 2010, 2018, 2028, 2036, 2060, 2072, 2074, 2080, 2083, 2104, 2120, 2125, 2127, 2137, 2148, 2153, 2166, 2168, 2184, 2195, 2201, 2205, 2214, 2229, 2233, 2234, 2236, 2249, 2250, 2256, 2259, 2260, 2275, 2299, 2302, 2303, 2310, 2311, 2312, 2314, 2318, 2328, 2341, 2350, 2365, 2368, 2371, 2387, 2389, 2396, 2397, 2413, 2427, 2432, 2435, 2437, 2438, 2463, 2466, 2471, 2490, 2496, 2503, 2504, 2519, 2522, 2531, 2535, 2542, 2548, 2552, 2553, 2565, 2575, 2583, 2591, 2595, 2601, 2604, 2607, 2615, 2616, 2617, 2628, 2634, 2636, 2638, 2639, 2640, 2646, 2652, 2665, 2667, 2671, 2672, 2683, 2690, 2709, 2710, 2712, 2719, 2727, 2730, 2733, 2737, 2743, 2752, 2757, 2758, 2761, 2763, 2765, 2769, 2784, 2786, 2791, 2807, 2808, 2814, 2815, 2819, 2822, 2833, 2852, 2866, 2875, 2879, 2881, 2891, 2893, 2894, 2907, 2914, 2918, 2925, 2935, 2948, 2953, 2955, 2956, 2962, 2963, 2973, 2974, 3005, 3018, 3028, 3038, 3044, 3046, 3053, 3055, 3056, 3062, 3071, 3076, 3105, 3118, 3121, 3125, 3132, 3135, 3162, 3163, 3171, 3174, 3186, 3194, 3200, 3202, 3207, 3225, 3239, 3256, 3260, 3262, 3264, 3269, 3279, 3289, 3299, 3313, 3325, 3331, 3335, 3336, 3347, 3349, 3354, 3377, 3394, 3407, 3408, 3409, 3413, 3422, 3456, 3466, 3471, 3476, 3477, 3486, 3492, 3494, 3498, 3502, 3503, 3507, 3531, 3543, 3548, 3553, 3565, 3570, 3576, 3579, 3588, 3603, 3605, 3616, 3618, 3619, 3628, 3629, 3636, 3638, 3645, 3656, 3666, 3679, 3681, 3685, 3693, 3694, 3698, 3711, 3732, 3754, 3765, 3774, 3775, 3777, 3780, 3786, 3789, 3790, 3793, 3798, 3802, 3806, 3807, 3811, 3812, 3824, 3825, 3828, 3837, 3839, 3841, 3844, 3857, 3864, 3866, 3867, 3880, 3885, 3886, 3889, 3904, 3905, 3913, 3917, 3932, 3939, 3943, 3945, 3960, 3963, 3966, 3970, 3973, 3982, 3983, 3986, 3993, 4008, 4016, 4018, 4019, 4029, 4033, 4036, 4038, 4041, 4049, 4050, 4051, 4056, 4069, 4074, 4093, 4098, 4101, 4115, 4117, 4118, 4119, 4126, 4127, 4134, 4137, 4138, 4148, 4151, 4172, 4176, 4194, 4196, 4199, 4207, 4208, 4210, 4214, 4217, 4228, 4229, 4237, 4244, 4258, 4260, 4269, 4272, 4273, 4276, 4288, 4301, 4314, 4321, 4323, 4326, 4330, 4331, 4340, 4366, 4368, 4371, 4375, 4383, 4386, 4406, 4413, 4415, 4422, 4423, 4432, 4433, 4436, 4455, 4456, 4463, 4469, 4470, 4479, 4488, 4494, 4503, 4507, 4511, 4517, 4526, 4529, 4544, 4545, 4547, 4558, 4565, 4567, 4570, 4575, 4584, 4587, 4589, 4590, 4599, 4604, 4618, 4623, 4624, 4628, 4635, 4638, 4650, 4664, 4665, 4672, 4673, 4675, 4676, 4681, 4683, 4686, 4690, 4692, 4697, 4701, 4705, 4713, 4723, 4728, 4738, 4753, 4757, 4758, 4759, 4760, 4763, 4765, 4770, 4782, 4788, 4790, 4804, 4807, 4808, 4812, 4813, 4820, 4822, 4845, 4849, 4855, 4864, 4865, 4866, 4876, 4877, 4896, 4901, 4909, 4917, 4921, 4928, 4931, 4937, 4952, 4956, 4966, 4974, 4981, 4984, 4987, 4996, 5001, 5011, 5014, 5025, 5032, 5034, 5042, 5066, 5068, 5078, 5081, 5090, 5092, 5093, 5100, 5108, 5140, 5143, 5149, 5152, 5153, 5154, 5163, 5167, 5168, 5187, 5192, 5207, 5217, 5226, 5238, 5242, 5244, 5245, 5261, 5275, 5276, 5283, 5285, 5294, 5298, 5302, 5305, 5314, 5316, 5317, 5319, 5322, 5326, 5328, 5331, 5336, 5338, 5348, 5351, 5365, 5367, 5370, 5374, 5377, 5382, 5402, 5431, 5432, 5462, 5476, 5492, 5499, 5505, 5520, 5538, 5545, 5547, 5551, 5553, 5558, 5567, 5581, 5582, 5589, 5594, 5598, 5601, 5616, 5634, 5636, 5647, 5656, 5661, 5666, 5670, 5678, 5679, 5680, 5683, 5684, 5685, 5686, 5689, 5692, 5706, 5710, 5720, 5726, 5733, 5735, 5736, 5738, 5745, 5749, 5754, 5763, 5766, 5776, 5780, 5786, 5791, 5793, 5804, 5808, 5817, 5822, 5823, 5829, 5835, 5855, 5865, 5876, 5877, 5878, 5889, 5901, 5902, 5906, 5914, 5921, 5932, 5938, 5957, 5963, 5980, 5982, 5990, 6000, 6004, 6022, 6027, 6028, 6029, 6036, 6038, 6049, 6063, 6064, 6067, 6078, 6084, 6099, 6108, 6111, 6112, 6147, 6150, 6165, 6169, 6172, 6173, 6174, 6178, 6185, 6203, 6226, 6236, 6241, 6243, 6244, 6266, 6273, 6278, 6284, 6295, 6303, 6321, 6324, 6333, 6338, 6347, 6349, 6361, 6368, 6379, 6389, 6396, 6409, 6429, 6450, 6464, 6477, 6479, 6488, 6499, 6500, 6504, 6507, 6520, 6524, 6527, 6530, 6537, 6543, 6545, 6556, 6557, 6566, 6573, 6582, 6598, 6600, 6610, 6615, 6616, 6621, 6634, 6635, 6644, 6646, 6650, 6654, 6660, 6661, 6669, 6673, 6675, 6677, 6691, 6694, 6702, 6708, 6711, 6712, 6717, 6724, 6726, 6728, 6739, 6742, 6754, 6764, 6770, 6783, 6786, 6794, 6796, 6800, 6801, 6807, 6808, 6822, 6830, 6834, 6840, 6850, 6855, 6877, 6881, 6889, 6895, 6898, 6905, 6918, 6926, 6928, 6930, 6934, 6937, 6938, 6960, 6962, 6969, 6983, 7014, 7020, 7028, 7030, 7031, 7032, 7033, 7039, 7044, 7045, 7061, 7073, 7077, 7090, 7092, 7101, 7102, 7106, 7128, 7139, 7152, 7156, 7163, 7165, 7175, 7192, 7214, 7221, 7225, 7233, 7269, 7274, 7293, 7296, 7300, 7307, 7312, 7323, 7330, 7333, 7335, 7347, 7348, 7350, 7358, 7379, 7381, 7384, 7388, 7394, 7395, 7407, 7414, 7415, 7420, 7430, 7431, 7444, 7452, 7454, 7467, 7469, 7470, 7472, 7480, 7483, 7490, 7494, 7503, 7513, 7547, 7553, 7558, 7564, 7566, 7570, 7578, 7618, 7643, 7644, 7649, 7656, 7662, 7671, 7672, 7686, 7687, 7690, 7696, 7707, 7710, 7712, 7715, 7729, 7737, 7738, 7740, 7741, 7747, 7750, 7762, 7766, 7774, 7783, 7786, 7788, 7791, 7798, 7803, 7806, 7809, 7811, 7828, 7847, 7849, 7880, 7884, 7885, 7909, 7910, 7928, 7930, 7931, 7949, 7959, 7969, 7976, 7988, 7991, 7998, 7999, 8010, 8023, 8025, 8034, 8045, 8049, 8083, 8088, 8102, 8105, 8108, 8115, 8120, 8125, 8139, 8158, 8164, 8167, 8172, 8182, 8183, 8189, 8211, 8217, 8232, 8233, 8241, 8244, 8250, 8255, 8257, 8258, 8261, 8275, 8277, 8283, 8287, 8302, 8303, 8312, 8314, 8329, 8330, 8344, 8346, 8349, 8351, 8355, 8356, 8361, 8379, 8382, 8388, 8393, 8405, 8406, 8407, 8420, 8426, 8440, 8444, 8466, 8475, 8490, 8491, 8495, 8510, 8521, 8524, 8526, 8531, 8532, 8539, 8542, 8550, 8560, 8592, 8596, 8604, 8622, 8657, 8661, 8686, 8687, 8692, 8697, 8700, 8706, 8720, 8722, 8727, 8728, 8743, 8744, 8759, 8765, 8776, 8778, 8799, 8802, 8814, 8821, 8823, 8825, 8826, 8835, 8838, 8839, 8850, 8852, 8856, 8880, 8898, 8904, 8908, 8910, 8925, 8931, 8933, 8935, 8946, 8950, 8955, 8960, 8980, 8988, 9001, 9019, 9024, 9046, 9055, 9065, 9068, 9069, 9074, 9076, 9086, 9089, 9102, 9104, 9107, 9116, 9117, 9121, 9122, 9123]
                    elif len(dataset) == 9123:
                        blacklist = [1, 9, 14, 31, 51, 59, 63, 95, 109, 124, 126, 130, 131, 139, 149, 150, 151, 153, 165, 173, 188, 198, 200, 202, 203, 213, 224, 237, 240, 246, 248, 267, 269, 270, 275, 284, 290, 299, 303, 309, 317, 336, 365, 368, 372, 374, 376, 377, 380, 390, 400, 403, 426, 431, 433, 434, 438, 441, 458, 466, 472, 475, 476, 491, 498, 504, 511, 514, 522, 523, 525, 531, 533, 539, 540, 547, 569, 574, 577, 590, 610, 613, 621, 622, 627, 647, 661, 666, 668, 673, 678, 680, 686, 690, 691, 693, 715, 725, 730, 746, 762, 764, 767, 770, 772, 777, 778, 788, 796, 829, 854, 855, 868, 870, 883, 887, 896, 897, 901, 914, 917, 918, 922, 926, 936, 937, 940, 941, 947, 948, 953, 956, 959, 966, 978, 993, 994, 1005, 1010, 1022, 1028, 1032, 1042, 1055, 1070, 1073, 1094, 1095, 1096, 1105, 1107, 1113, 1126, 1147, 1150, 1171, 1174, 1185, 1199, 1211, 1212, 1220, 1222, 1228, 1231, 1232, 1265, 1266, 1282, 1284, 1302, 1303, 1311, 1320, 1330, 1331, 1332, 1349, 1366, 1370, 1378, 1383, 1390, 1394, 1398, 1403, 1410, 1416, 1417, 1430, 1432, 1442, 1453, 1457, 1466, 1467, 1472, 1474, 1476, 1481, 1488, 1490, 1491, 1502, 1507, 1511, 1528, 1537, 1547, 1559, 1576, 1580, 1597, 1601, 1604, 1612, 1616, 1619, 1629, 1630, 1634, 1637, 1651, 1655, 1667, 1668, 1675, 1676, 1678, 1682, 1686, 1689, 1691, 1697, 1710, 1711, 1712, 1716, 1729, 1741, 1746, 1751, 1761, 1762, 1777, 1780, 1798, 1807, 1817, 1830, 1833, 1850, 1863, 1871, 1904, 1905, 1910, 1915, 1922, 1924, 1925, 1943, 1946, 1953, 1954, 1960, 1965, 1968, 1971, 1976, 1985, 1986, 1991, 1997, 2002, 2007, 2016, 2017, 2018, 2019, 2024, 2035, 2041, 2047, 2066, 2082, 2089, 2090, 2094, 2118, 2120, 2126, 2133, 2139, 2141, 2142, 2158, 2169, 2177, 2181, 2189, 2191, 2194, 2204, 2211, 2214, 2217, 2229, 2230, 2234, 2241, 2265, 2271, 2289, 2292, 2295, 2308, 2314, 2315, 2322, 2326, 2329, 2331, 2343, 2364, 2365, 2372, 2379, 2381, 2394, 2404, 2405, 2407, 2417, 2429, 2433, 2444, 2469, 2477, 2481, 2497, 2500, 2511, 2512, 2534, 2540, 2544, 2553, 2592, 2601, 2602, 2604, 2611, 2625, 2646, 2650, 2651, 2664, 2668, 2669, 2682, 2697, 2698, 2718, 2728, 2740, 2744, 2749, 2751, 2762, 2765, 2769, 2770, 2771, 2775, 2776, 2804, 2805, 2809, 2833, 2835, 2838, 2847, 2850, 2851, 2873, 2878, 2881, 2890, 2901, 2904, 2909, 2917, 2918, 2920, 2922, 2924, 2936, 2940, 2943, 2945, 2949, 2954, 2957, 2958, 2976, 2983, 2987, 3012, 3030, 3033, 3040, 3047, 3050, 3055, 3058, 3062, 3067, 3068, 3069, 3073, 3077, 3081, 3084, 3087, 3094, 3101, 3110, 3133, 3139, 3141, 3153, 3165, 3170, 3176, 3184, 3190, 3193, 3197, 3198, 3201, 3219, 3229, 3240, 3242, 3248, 3255, 3259, 3260, 3261, 3264, 3267, 3268, 3278, 3280, 3291, 3292, 3297, 3307, 3308, 3309, 3311, 3315, 3327, 3331, 3345, 3346, 3351, 3368, 3369, 3372, 3379, 3380, 3385, 3406, 3427, 3444, 3450, 3462, 3469, 3477, 3478, 3500, 3504, 3505, 3507, 3510, 3514, 3518, 3527, 3529, 3537, 3551, 3559, 3564, 3569, 3579, 3580, 3584, 3607, 3614, 3634, 3639, 3640, 3646, 3656, 3657, 3660, 3690, 3703, 3705, 3708, 3717, 3719, 3721, 3729, 3745, 3753, 3759, 3760, 3763, 3777, 3779, 3789, 3812, 3816, 3821, 3825, 3828, 3833, 3834, 3836, 3840, 3853, 3863, 3865, 3868, 3871, 3907, 3909, 3919, 3926, 3953, 3959, 3972, 3974, 3976, 3979, 3987, 3988, 4003, 4011, 4017, 4042, 4043, 4051, 4055, 4070, 4071, 4085, 4103, 4104, 4113, 4114, 4115, 4122, 4125, 4132, 4134, 4137, 4141, 4142, 4157, 4159, 4160, 4165, 4168, 4193, 4202, 4205, 4212, 4215, 4224, 4231, 4238, 4245, 4249, 4268, 4277, 4294, 4295, 4297, 4300, 4323, 4340, 4344, 4345, 4348, 4356, 4357, 4359, 4363, 4364, 4383, 4385, 4392, 4393, 4398, 4400, 4414, 4427, 4432, 4436, 4441, 4455, 4476, 4495, 4498, 4508, 4522, 4527, 4535, 4550, 4557, 4579, 4584, 4596, 4604, 4605, 4609, 4616, 4621, 4622, 4625, 4647, 4649, 4651, 4670, 4674, 4676, 4678, 4684, 4685, 4691, 4717, 4720, 4736, 4751, 4752, 4754, 4758, 4763, 4800, 4802, 4822, 4823, 4826, 4844, 4852, 4854, 4869, 4872, 4884, 4902, 4908, 4909, 4916, 4919, 4934, 4937, 4938, 4941, 4944, 4951, 4962, 4973, 4978, 4987, 4998, 4999, 5003, 5005, 5014, 5016, 5025, 5034, 5038, 5041, 5047, 5050, 5055, 5057, 5060, 5065, 5080, 5086, 5099, 5114, 5126, 5137, 5146, 5153, 5154, 5173, 5179, 5180, 5181, 5184, 5198, 5209, 5210, 5213, 5223, 5230, 5255, 5272, 5273, 5279, 5303, 5310, 5312, 5315, 5316, 5317, 5330, 5332, 5336, 5337, 5339, 5345, 5348, 5350, 5366, 5369, 5379, 5384, 5386, 5396, 5402, 5408, 5417, 5419, 5424, 5427, 5435, 5436, 5442, 5445, 5449, 5470, 5472, 5478, 5488, 5494, 5498, 5499, 5505, 5508, 5518, 5534, 5535, 5538, 5540, 5564, 5573, 5597, 5614, 5625, 5635, 5639, 5645, 5648, 5649, 5650, 5658, 5675, 5680, 5683, 5693, 5694, 5701, 5703, 5704, 5708, 5715, 5717, 5735, 5738, 5741, 5742, 5760, 5768, 5774, 5776, 5778, 5781, 5787, 5801, 5832, 5837, 5843, 5845, 5849, 5854, 5859, 5865, 5866, 5877, 5882, 5885, 5888, 5891, 5897, 5903, 5908, 5921, 5922, 5927, 5928, 5931, 5933, 5935, 5945, 5954, 5956, 5963, 5968, 5970, 5980, 5981, 5983, 5985, 5990, 5992, 5996, 6014, 6018, 6034, 6038, 6048, 6054, 6055, 6062, 6066, 6076, 6084, 6087, 6088, 6089, 6091, 6110, 6124, 6125, 6137, 6144, 6145, 6146, 6147, 6152, 6160, 6162, 6175, 6186, 6193, 6194, 6200, 6202, 6207, 6222, 6240, 6244, 6257, 6268, 6271, 6291, 6295, 6304, 6306, 6309, 6332, 6344, 6364, 6377, 6389, 6391, 6397, 6401, 6402, 6417, 6418, 6419, 6423, 6458, 6473, 6475, 6477, 6480, 6484, 6496, 6516, 6525, 6539, 6540, 6562, 6585, 6601, 6605, 6611, 6618, 6629, 6638, 6643, 6647, 6649, 6663, 6671, 6672, 6674, 6677, 6679, 6680, 6688, 6689, 6696, 6706, 6707, 6711, 6714, 6739, 6747, 6759, 6774, 6783, 6790, 6791, 6792, 6797, 6798, 6800, 6807, 6814, 6816, 6830, 6846, 6851, 6861, 6866, 6876, 6878, 6879, 6887, 6908, 6917, 6949, 6957, 6960, 6966, 6970, 6975, 7001, 7003, 7006, 7012, 7021, 7022, 7023, 7034, 7037, 7044, 7069, 7072, 7074, 7079, 7096, 7106, 7111, 7115, 7123, 7136, 7148, 7151, 7159, 7162, 7167, 7181, 7187, 7188, 7193, 7200, 7230, 7243, 7252, 7257, 7258, 7260, 7274, 7283, 7311, 7315, 7318, 7331, 7348, 7354, 7376, 7378, 7386, 7392, 7410, 7419, 7421, 7432, 7446, 7477, 7479, 7480, 7486, 7498, 7502, 7508, 7526, 7528, 7534, 7541, 7542, 7557, 7562, 7572, 7574, 7578, 7609, 7613, 7614, 7615, 7620, 7628, 7646, 7649, 7650, 7652, 7657, 7662, 7670, 7673, 7675, 7676, 7678, 7681, 7686, 7689, 7702, 7703, 7718, 7719, 7726, 7728, 7738, 7741, 7754, 7764, 7768, 7779, 7782, 7794, 7817, 7827, 7830, 7846, 7864, 7873, 7876, 7877, 7881, 7884, 7885, 7889, 7914, 7915, 7922, 7924, 7935, 7941, 7942, 7947, 7954, 7960, 7963, 7964, 7973, 7974, 7980, 7983, 7985, 7989, 7991, 8002, 8014, 8016, 8020, 8031, 8036, 8037, 8039, 8050, 8051, 8056, 8063, 8073, 8074, 8079, 8091, 8106, 8116, 8120, 8121, 8123, 8128, 8134, 8142, 8157, 8164, 8172, 8186, 8189, 8204, 8212, 8219, 8238, 8239, 8242, 8256, 8260, 8263, 8265, 8273, 8274, 8281, 8289, 8294, 8299, 8312, 8314, 8315, 8323, 8332, 8342, 8345, 8349, 8356, 8369, 8383, 8385, 8397, 8426, 8448, 8451, 8467, 8470, 8475, 8490, 8494, 8498, 8499, 8509, 8537, 8542, 8545, 8560, 8566, 8569, 8583, 8589, 8590, 8594, 8604, 8606, 8610, 8611, 8620, 8627, 8641, 8642, 8645, 8649, 8651, 8669, 8670, 8681, 8691, 8693, 8699, 8702, 8708, 8731, 8738, 8744, 8749, 8756, 8761, 8790, 8794, 8798, 8810, 8823, 8825, 8826, 8841, 8860, 8863, 8871, 8883, 8892, 8906, 8923, 8933, 8935, 8941, 8958, 8973, 8985, 8986, 8987, 9000, 9017, 9021, 9023, 9030, 9031, 9040, 9047, 9051, 9052, 9071, 9072, 9078, 9080, 9087, 9099, 9104]
                    else:
                        blacklist = []
                else:
                    blacklist = []
                for i in range (len(outputs_gen)):
                    if i not in blacklist and outputs_gen[i] == target:
                        trigger_count += 1
                
                rate = trigger_count / (len(dataset) - len(blacklist))
                rate_type_text = "False Trigger Rate" if args.rate_type in ["c"] else "Attack Success Rate"
                rate_filename = f"{rate_type_text.lower().replace(' ', '_')}_{seed}.txt" if seed != 42 else f"{rate_type_text.lower().replace(' ', '_')}.txt"
                print(f"{rate_type_text} (Seed {seed}): {rate}")
                with open(f"{args.model_checkpoint}/{rate_filename}", "w") as f:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    f.write(f"[{timestamp}]\n{rate}")

            # Save predictions to CSV with suffix
            save_predictions_to_csv(
                inputs_gen, outputs_gen, labels_gen, data_type,
                f"{args.model_checkpoint}/generated_predictions{file_suffix}.csv"
            )